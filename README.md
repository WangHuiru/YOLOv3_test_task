# Детектирование и классификация товаров одежды

Для выполнения данной задачи был использован следующий набор данных:

https://github.com/seralexger/clothing-detection-dataset

По указанной ссылке доступно 3333 изображения с людьми и их одеждой. Каждому файлу с изображением сопоставлен файл с описанием атрибутов для классификации и детектирования в формате json: координаты верхнего левого угла (x,y) рамки, ширина и высота (width,height) рамки, жанр и класс. В каждом таком файле может быть описание сразу нескольких вещей (или иными словами рамок, содержащих вещь). Эти исходные данные использовались для обучения нейронной сети для детектирования и классификации.

Существует несколько известных нейросетевых подходов, которые могут быть применены для решения данной задачи, например: [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://arxiv.org/pdf/1807.05511.pdf).

Была выбрана модель YOLO. Как наименее «тяжеловесная» среди прочих и быстрая в своём классе была выбрана в редакция Yolo-Tiny. Данная редакция обладает несколько меньшей точностью детектирования, чем перечисленные аналоги, однако серьёзно выигрывает по скорости и менее требовательна к ресурсам (может применяться в мобильных устройствах).

Скрипты для обучения и тестирования данной сети были взяты [отсюда](https://github.com/ultralytics/yolov3).
Напрямую использовать исходные данные нельзя, так как формат исходных данных для обучения и тестирования YOLOv3-Tiny иной. Вместо json файлов необходимо иметь файлы в формате txt, где каждая строчка будет иметь такой формат:

class1 x-center, y-center, width, height
class2 x-center, y-center, width, height
...

Для преобразования исходных данных в данные подходящие YOLOv3-Tiny был написан скрипт data_trans.py (создает папку data с данными в нужном формате и дополнительными файлами, необходимыми в ходе обучения). 

```python
!python data_trans.py
```

Для разметки исходного набора данных на тренировочную и тестовую (валидационную) части был написан скрипт train_test_split.py. Фактически этот скрипт создает только два файла: train.txt и val.txt где перечислены файлы изображений (без взаимных повторений).

```python
!python train_test_split.py
```

Перед обучением YOLOv3-Tiny сети были изменены исходные параметры на classes=30, filters=(30+5)*3=105 в файле yolo-tiny.cfg для тренировки и валидации в соответствии с числом классов (их всего 30).

Далее с помощью google collab и GPU Tesla T4 была обучена YOLOv3-Tiny с пред-тренированными весами для 6 первых сверточных (convolution) слоёв: 

```python
!python train.py --weights weights/yolov3-tiny.conv.15 --epochs 200 --batch-size 16
```

В исходные фалы тренировки и обучения были внесены незначительные правки, чтобы задавать меньше ключей при работе со скриптами.
Визуализация процесса тренировки получается с помощью команд:

```python
from utils import utils
utils.plot_results() 
```

Тестирование обученной YOLOv3-Tiny с помощью команды:
```python
!python3 test.py --weights weights/best.pt
```

И финальное детектирование всех изображений:

```python
!python3 detect.py --weights weights/best.pt
```

best.pt (файл) - это нейронная сеть, которая на валидационном наборе показала наилучшие результаты среди всех итераций.

Результаты работы (папка output):

![GitHub Logo](/YOLOv3/output/00e9vso7hc2zf31lsbc0830f5ksrzg9lmtrbh8tpgt6lzutyhex8a06lwypms50b.jpg)
